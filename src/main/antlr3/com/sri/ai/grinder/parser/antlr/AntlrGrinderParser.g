parser grammar AntlrGrinderParser;

options {

    // Default language but name it anyway
    //
    language  = Java;

    // Produce an AST
    //
    output    = AST;

    // Use the vocabulary generated by the accompanying
    // lexer. Maven knows how to work out the relationship
    // between the lexer and parser and will build the 
    // lexer before the parser. It will also rebuild the
    // parser if the lexer changes.
    //
    tokenVocab = AntlrGrinderLexer;
    
    ASTLabelType = CommonTree;
    
    backtrack = true;
    memoize = true;
}

/*
    The parser takes the token stream from the parser, validates
    them against the defined grammar rules, and outputs an AST
    composed of ANTLR's native CommonTree node type.
    
    The grammar rules are arranged in a cascade that starts with
    the lowest precedence rule at the top and the highest precedence
    rule at the bottom.  Each rule has a pass through to the next
    rule in precedence.
    
    For each node in the output, a type is assigned depending on
    which grammar rule is matched.  For some nodes types, one of the
    token types is used.  These are cases, when there is one terminal
    symbol in the grammar rule and it is unique.  In other cases, an
    imaginary token is defined and used.  The imaginary tokens are
    defined in the "tokens" section.  Sometimes multiple imaginary
    tokens are defined for a given rule to distinguish between 
    variants with optional phrases present or absent or in cases that 
    there are child nodes for rules that need to be defined.
    
    Adding new grammar rules
    ------------------------
    Insert the new rules in the appropriate locations in the grammar
    rule chain according to the precedence order of the rule.  In the
    rules, list the tokens in order.  Use the terminal symbols defined
    in the lexer rules.  In the position of non-terminal symbols, put
    either the current rule name or the next higher precedence rule, 
    depending on if you wish to allow consecutive calls of the same
    rule.  e.g. Whether you want to allow cases like "not not x".
    (There are a couple of occasions where expr is used in the 
    non-terminal symbol locations, but these need to be carefully
    considered because they do have effects on the order of precedence.)
    
    Make sure the rules have a way to pass through to the next rule 
    in the chain.  You can either do this with the optional or 
    0-or-more symbols ("?" and "*") or make an alternate form of the
    rule that just calls the next rule in the chain.

    In ANTLR, there are two ways to specify the structure of the generated
    node for a rule.  In simple cases, you can specify one token as the
    root for the node:
        foo : next_rule FOO^ next_rule IGNORE!
    In the example, FOO will be the type for generated node and the other
    tokens will be the children of the node, except for IGNORE node which
    is marked to be ignored.

    The other way to specify the structure of the generated node for
    a rule is with rewrite rules.  Here's the same rule as above, done
    with rewrite rules.
        foo : a=next_rule FOO b=next_rule IGNORE -> ^(FOO $a $b)

    If there are optional parts to a grammar rule, it is easiest to create
    multiple alternatives to the rule instead of using the ? symbol.
    That way you can type the output nodes differently and makes it
    easier to differentiate the two paths.  For example:
        foo : FOO next_rule                 -> ^(FOO1 next_rule)
            | FOO next_rule COLON next_rule -> ^(FOO2 next_rule+)
    In this example, there are two variants of the foo rule, one with
    an optional second parameter.  Instead of using the ? symbol for
    the optional part, there are two alternatives for the rule, each
    with its own rewrite rule.  Note: that the type for the generated
    output for the two alternatives is different to make differentiating
    between the two alternatives easier in later steps of the parsing 
    process.  The next paragraph talks more about node types.

    Make sure the output of the rule has a unique node type.  You can
    either use an existing token type or you can create an imaginary
    token to use as the type identifier for the rule's node type.  New
    imaginary nodes should be added in the "tokens" section.

    Rules that utilize new terminal symbols should have entries added
    in the "atomic_symbol" rule so that function form and atomics forms 
    of the terminal symbols can be captured.  (Currently, only the 
    terminal symbols of rules that use only one terminal symbol are in 
    the "function" and "atomic_symbol" rules.)
*/
tokens {
    PREVIOUSMESSAGETO ;
    MESSAGETO ;
    IFTHENELSE ;
    THEREEXISTS ;
    FORALL ;
    NEIGHBORSOF ;
    NEIGHBORSOFVARIABLE ;
    NEIGHBORSOFFACTOR ;
    UNDERSCORESET ;
    VALUEOF ;
    SQUAREBRACKET ;
    SET ;
    SETCOMPREHENSION1 ;
    SETCOMPREHENSION2 ;
    SETCOMPREHENSION3 ;
    MULTISET ;
    MULTISETCOMPREHENSION1 ;
    MULTISETCOMPREHENSION2 ;
    MULTISETCOMPREHENSION3 ;
    COMPREHENSION_ON ;
    COMPREHENSION_VERT_BAR ;
    SEQUENCE ;
    TUPLE ;
    FUNCTION ;
    KLEENE ;
    SYMBOL ;
    SYMBOL_EXPRESSION ;
}

@header {

    package com.sri.ai.grinder.parser.antlr;
}

@members {

/** Makes parser fail on first error. */
//@Override
//protected void mismatch(IntStream input, int ttype, BitSet follow)
//    throws RecognitionException {
//    throw new MismatchedTokenException(ttype, input);
//}

/** Makes parser fail on first error. */
@Override
public Object recoverFromMismatchedSet(IntStream input, RecognitionException e, BitSet follow)
    throws RecognitionException {
    throw e;
    //return null;
}

/** Makes parser fail on first error. */
protected Object recoverFromMismatchedToken(IntStream input, int ttype, BitSet follow)
    throws RecognitionException {
    throw new MismatchedTokenException(ttype, input);
}
}

// Alter code generation so catch-clauses get replace with this action.
@rulecatch {
catch (RecognitionException e) { throw e; }
}

start 
    : expr EOF!
    ;

expr
    : previousmessage
    ;

// This is a kludge for getting around an issue (possible bug?) using labels in tree rewrite rules.
expr2
    : previousmessage
    ;

previousmessage
    : PREVIOUS MESSAGE TO a=previousmessage FROM b=previousmessage -> ^(PREVIOUSMESSAGETO $a $b)
    | message
    ;

message
    : MESSAGE TO a=message FROM b=message -> ^(MESSAGETO $a $b)
    | singlearrow
    ;

singlearrow
    : lambda (SINGLE_ARROW^ lambda)*
//    : lambda (SINGLE_ARROW^ lambda)*
    ;

lambda
    : LAMBDA kleene COLON lambda -> ^(LAMBDA kleene lambda)
    | ifthenelse
    ;

ifthenelse
    : IF a=expr THEN b=expr ELSE c=expr -> ^(IFTHENELSE $a $b $c)
    | forall
    ;

forall
    : FOR ALL a=forall COLON b=forall -> ^(FORALL $a $b)
    | exists
    ;

exists
    : THERE EXISTS a=exists COLON b=exists -> ^(THEREEXISTS $a $b)
    | eg
    ;

eg
    : leg (ARROW^ expr)*
    ;

leg
    : or (DOUBLE_ARROW^ expr)*
    ;

or
    : and (OR^ and)*               // Uncomment this line to skip node consolidation in parser.
//    : and (OR and)+ -> ^(OR and+)  // Uncomment these two line to do node consolidation in parser.
//    | and                          // Note: doing it in the parser can cause the build time and memory usage to explode.
    ;

and
    : is (AND^ is)*                // Uncomment this line to skip node consolidation in parser.
//    : is (AND is)+ -> ^(AND is+)  // Uncomment these two line to do node consolidation in parser.
//    | is                          // Note: doing it in the parser can cause the build time and memory usage to explode.
    ;

is
    : equal (IS^ equal)*
    ;

equal
    : notequal (EQUAL^ notequal)*                     // Uncomment this line to skip node consolidation in parser.
//    : notequal (EQUAL notequal)+ -> ^(EQUAL notequal+)  // Uncomment these two line to do node consolidation in parser.
//    | notequal                                          // Note: doing it in the parser can cause the build time and memory usage to explode.
    ;

notequal
    : greaterthan (NOT_EQUAL^ greaterthan)*
    ;

greaterthan
    : greaterthanequal (GREATER_THAN^ greaterthanequal)*
    ;

greaterthanequal
    : lessthan (GREATER_THAN_EQUAL^ lessthan)*
    ;

lessthan
    : lessthanequal (LESS_THAN^ lessthanequal)*
    ;

lessthanequal
    : in (LESS_THAN_EQUAL^ in)*
    ;

in
    : union (IN^ union)*
    ;

union
    : intersection (UNION^ intersection)*                 // Uncomment this line to skip node consolidation in parser.
//    : intersection (UNION intersection)+ -> ^(UNION intersection+)  // Uncomment these two line to do node consolidation in parser.
//    | intersection                                  // Note: doing it in the parser can cause the build time and memory usage to explode.
    ;

intersection
    : plus (INTERSECTION^ plus)*                 // Uncomment this line to skip node consolidation in parser.
//    : plus (INTERSECTION plus)+ -> ^(INTERSECTION plus+)  // Uncomment these two line to do node consolidation in parser.
//    | plus                                  // Note: doing it in the parser can cause the build time and memory usage to explode.
    ;

plus
    : dash (PLUS^ dash)*                 // Uncomment this line to skip node consolidation in parser.
//    : dash (PLUS dash)+ -> ^(PLUS dash+)  // Uncomment these two line to do node consolidation in parser.
//    | dash                                // Note: doing it in the parser can cause the build time and memory usage to explode.
    ;

dash
    : minus (DASH^ minus)*
    ;

minus
    : multiply (MINUS^ multiply)*
    ;


multiply
    : divide (TIMES^ divide)*                   // Uncomment this line to skip node consolidation in parser.
//    : divide (TIMES divide)+ -> ^(TIMES divide+)  // Uncomment these two line to do node consolidation in parser.
//    | divide                                      // Note: doing it in the parser can cause the build time and memory usage to explode.
    ;


divide
    : carat (DIVIDE^ carat)*
    ;


carat
    : negative (CARAT^ negative)*
    ;

negative
    // Using "negative" instead of expected "not" so that we can support cases like "--x".
    : DASH^ negative
    | not
    ;

not
    // Using "not" instead of expected "neighborof" so that we can support cases like "not not x".
    : NOT^ not
    | neighborof
    ;

neighborof
    // Using "neighborof" instead of expected "neighborvariable" so that we can support cases like "neighbors of neighbors of x from y from z".
    : NEIGHBORS OF a=neighborof FROM b=neighborof -> ^(NEIGHBORSOF $a $b)
    | neighborvariable
    ;

neighborvariable
    // Using "neighborvariable" instead of expected "neighborfactor" so that we can support cases like "neighbors of variable neighbors of variable x".
    : NEIGHBORS OF VARIABLE neighborvariable -> ^(NEIGHBORSOFVARIABLE neighborvariable)
    | neighborfactor
    ;


neighborfactor
    // Using "neighborfactor" instead of expected "value" so that we can support cases like "neighbors of factor neighbors of factor x".
    : NEIGHBORS OF FACTOR neighborfactor -> ^(NEIGHBORSOFFACTOR neighborfactor)
    | cases
    ;

cases  // Can't call this "case" because it's a Java keyword!
    : CASE cases kleenecolonpair -> ^(CASE cases kleenecolonpair)
    | index
    ;

index
    : INDEX OF a=index IN b=index -> ^(INDEX $a $b)
    | occurs
    ;

occurs
    : underscoreset (OCCURS^ IN! underscoreset)*
    ;

underscoreset
    : underscore UNDERSCORE_OPEN_CURLY expr COLON expr CLOSE_CURLY -> ^(UNDERSCORESET underscore expr+)
    | underscore
    ;

underscore
    : value (UNDERSCORE^ value)*
    ;

squarebracket
    : OPEN_SQUARE expr CLOSE_SQUARE -> ^(SQUAREBRACKET expr)
    | set
    ;

set
    : OPEN_CURLY kleene CLOSE_CURLY -> ^(SET kleene)
    | OPEN_CURLY OPEN_PAREN ON kleene CLOSE_PAREN expr CLOSE_CURLY -> ^(SETCOMPREHENSION1 ^(COMPREHENSION_ON kleene) expr)
    | OPEN_CURLY OPEN_PAREN ON kleene CLOSE_PAREN expr VERT_BAR expr2 CLOSE_CURLY -> ^(SETCOMPREHENSION2 ^(COMPREHENSION_ON kleene) expr ^(COMPREHENSION_VERT_BAR expr2))
    | OPEN_CURLY expr VERT_BAR expr2 CLOSE_CURLY -> ^(SETCOMPREHENSION3 expr ^(COMPREHENSION_VERT_BAR expr2))
    | multiset
    ;

multiset
    : OPEN_DOUBLE_CURLY kleene CLOSE_DOUBLE_CURLY -> ^(MULTISET kleene)
    | OPEN_DOUBLE_CURLY OPEN_PAREN ON kleene CLOSE_PAREN expr CLOSE_DOUBLE_CURLY -> ^(MULTISETCOMPREHENSION1 ^(COMPREHENSION_ON kleene) expr)
    | OPEN_DOUBLE_CURLY OPEN_PAREN ON kleene CLOSE_PAREN expr VERT_BAR expr2 CLOSE_DOUBLE_CURLY -> ^(MULTISETCOMPREHENSION2 ^(COMPREHENSION_ON kleene) expr ^(COMPREHENSION_VERT_BAR expr2))
    | OPEN_DOUBLE_CURLY expr VERT_BAR expr2 CLOSE_DOUBLE_CURLY -> ^(MULTISETCOMPREHENSION3 expr ^(COMPREHENSION_VERT_BAR expr2))
    | sequence
    ;

sequence
    : VERT_BAR expr VERT_BAR -> ^(SEQUENCE expr)
    | tuple
    ;

tuple
    : OPEN_PAREN kleene2 CLOSE_PAREN -> ^(TUPLE kleene2)
    | function
    ;

function
    : symbol_expression OPEN_PAREN (expr ( COMMA expr )*)? CLOSE_PAREN                  -> ^(FUNCTION symbol_expression expr*)
    | symbol_expression
    ;

symbol_expression
    : LESS_THAN expr GREATER_THAN -> ^(SYMBOL_EXPRESSION expr)
    | atomic_symbol
    ;

atomic_symbol
    : SINGLE_ARROW         -> ^(SYMBOL ID[$SINGLE_ARROW.text])
    | ARROW                -> ^(SYMBOL ID[$ARROW.text])
    | DOUBLE_ARROW         -> ^(SYMBOL ID[$DOUBLE_ARROW.text])
    | OR                   -> ^(SYMBOL ID[$OR.text])
    | AND                  -> ^(SYMBOL ID[$AND.text])
    | IS                   -> ^(SYMBOL ID[$IS.text])
    | EQUAL                -> ^(SYMBOL ID[$EQUAL.text])
    | NOT_EQUAL            -> ^(SYMBOL ID[$NOT_EQUAL.text])
    | GREATER_THAN         -> ^(SYMBOL ID[$GREATER_THAN.text])
    | GREATER_THAN_EQUAL   -> ^(SYMBOL ID[$GREATER_THAN_EQUAL.text])
    | LESS_THAN            -> ^(SYMBOL ID[$LESS_THAN.text])
    | LESS_THAN_EQUAL      -> ^(SYMBOL ID[$LESS_THAN_EQUAL.text])
    | IN                   -> ^(SYMBOL ID[$IN.text])
    | UNION                -> ^(SYMBOL ID[$UNION.text])
    | INTERSECTION         -> ^(SYMBOL ID[$INTERSECTION.text])
    | PLUS                 -> ^(SYMBOL ID[$PLUS.text])
    | DASH                 -> ^(SYMBOL ID[$DASH.text])
    | MINUS                -> ^(SYMBOL ID[$MINUS.text])
    | TIMES                -> ^(SYMBOL ID[$TIMES.text])
    | DIVIDE               -> ^(SYMBOL ID[$DIVIDE.text])
    | CARAT                -> ^(SYMBOL ID[$CARAT.text])
    | NOT                  -> ^(SYMBOL ID[$NOT.text])
    | UNDERSCORE           -> ^(SYMBOL ID[$UNDERSCORE.text])
    | atom
    ;

atom
    : ID -> ^(SYMBOL ID)
    | STRING -> ^(SYMBOL ID[$STRING.text])
    | OPEN_PAREN! expr CLOSE_PAREN!
    ;

// For cases where you need 0 or more items in the kleene
kleene
    : (expr ( COMMA expr )+)? -> ^(KLEENE expr*)
    | expr -> expr
    ;

// For cases where you need 1 or more items in the kleene
kleene1
    : expr ( COMMA expr )+ -> ^(KLEENE expr*)
    | expr -> expr
    ;


// For cases where you need at least two items in the kleene
kleene2
    : expr ( COMMA expr )+ -> ^(KLEENE expr+)
    ;

kleenecolonpair
//    : (colonpair ( COMMA colonpair )+)? -> ^(KLEENE colonpair*)
    : (colonpair ( COMMA colonpair )+) -> ^(KLEENE colonpair*)
    | colonpair -> colonpair
    ;

colonpair
    : expr COLON^ expr
    ;




